# EU AI Act - Artificial Intelligence Regulation

## Overview

The EU AI Act (Regulation 2024/1689) is the world's first comprehensive legal framework for artificial intelligence. It establishes a risk-based approach to AI regulation.

**Entry into force:** August 1, 2024
**Official reference:** Regulation (EU) 2024/1689

## Risk Classification

### Unacceptable Risk (Prohibited)
AI systems posing unacceptable risks are banned outright.

**Prohibited practices (Article 5):**
- Social scoring by public authorities
- Real-time remote biometric identification in public spaces (with limited exceptions)
- Biometric categorization inferring sensitive attributes
- Emotion recognition in workplaces and education (with exceptions)
- Scraping facial images for recognition databases
- Subliminal techniques causing harm
- Exploitation of vulnerabilities (age, disability, social/economic situation)

### High-Risk AI Systems
AI systems with significant impact on health, safety, or fundamental rights.

**Category 1 - Safety Components (Article 6(1)):**
AI systems that are safety components of products covered by EU harmonization legislation:
- Machinery (Machinery Regulation)
- Medical devices
- Toys
- Lifts
- Personal protective equipment
- Radio equipment
- Civil aviation

**Category 2 - Annex III Areas (Article 6(2)):**
- Biometric identification and categorization
- Critical infrastructure management (water, gas, electricity, transport)
- Education and vocational training
- Employment, worker management
- Access to essential services (credit, insurance, social benefits)
- Law enforcement
- Migration and border control
- Administration of justice

### Limited Risk
AI systems with transparency obligations only.
- Chatbots (must disclose AI nature)
- Emotion recognition systems (must inform users)
- Biometric categorization (must inform)
- Deepfakes (must label as AI-generated)

### Minimal Risk
No specific requirements. Examples:
- Spam filters
- AI-enabled video games
- Inventory management

## High-Risk AI Requirements

### Article 9 - Risk Management System
Continuous, iterative process throughout AI system lifecycle:
- Identify and analyze known/foreseeable risks
- Estimate and evaluate risks
- Implement mitigation measures
- Document and update regularly

### Article 10 - Data Governance
Training, validation, and testing data must:
- Be relevant, representative, and free of errors
- Have appropriate statistical properties
- Consider specific geographical, contextual, behavioral settings
- Address potential biases

### Article 11 - Technical Documentation
Comprehensive documentation before market placement:
- General description and intended purpose
- Design specifications
- Development methodology
- Data requirements
- Testing procedures
- Human oversight measures

### Article 12 - Record-Keeping
Automatic logging capabilities for:
- Operating period
- Reference database versions
- Input data leading to risk
- Performance monitoring data

### Article 13 - Transparency
Instructions for use including:
- Provider identity
- Characteristics and limitations
- Performance metrics
- Intended purpose and prohibited uses
- Human oversight measures
- Expected accuracy levels

### Article 14 - Human Oversight
Measures enabling humans to:
- Understand AI system capabilities
- Correctly interpret outputs
- Decide not to use or override
- Interrupt operation (stop button)

### Article 15 - Accuracy, Robustness, Cybersecurity
Systems must achieve:
- Appropriate accuracy levels
- Robustness against errors and inconsistencies
- Resilience against manipulation (adversarial attacks)
- Cybersecurity throughout lifecycle

## Conformity Assessment

### Self-Assessment
Most high-risk systems can be assessed by providers:
- Complete technical documentation
- Establish quality management system
- Sign EU Declaration of Conformity
- Apply CE marking
- Register in EU database

### Third-Party Assessment
Required for:
- Biometric identification systems
- Remote biometric categorization
- Critical infrastructure AI (optional but encouraged)

### Notified Bodies
Designated organizations performing conformity assessments.

## Timeline

| Date | Milestone |
|------|-----------|
| August 2024 | Entered into force |
| February 2025 | Prohibited AI practices applicable |
| August 2025 | General-purpose AI rules applicable |
| August 2025 | Governance rules applicable |
| August 2026 | Full high-risk rules applicable |
| August 2027 | Certain embedded AI rules |

## Industrial AI Considerations

### Machinery Integration
AI used as safety components in machinery:
- Subject to high-risk requirements
- Must comply with Machinery Regulation
- Conformity assessment may be combined

### Field Service AI
AI assistants for field technicians typically:
- Not high-risk unless controlling critical infrastructure
- May have transparency obligations
- Should document limitations and intended use

### Predictive Maintenance AI
AI predicting equipment failure:
- May be high-risk if safety-critical
- Data governance requirements apply
- Human oversight required for critical decisions

## Penalties

Member states establish penalties:
- Up to 35 million EUR or 7% global turnover for prohibited AI
- Up to 15 million EUR or 3% for high-risk violations
- Up to 7.5 million EUR or 1.5% for incorrect information
